<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content="width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */

    a {
      color: #1772d0;
      text-decoration: none;
    }

    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }

    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
    }

    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }

    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }

    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 17px;
    }

    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }

    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }

    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="files/JHU_icon.jpg">
  <title>Shao-Yuan Lo</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Shao-Yuan Lo &nbsp 羅紹元</name>
              </p>
              <p align="justify">
				I am an Assistant Professor at <a href="https://www.ntu.edu.tw/english/">National Taiwan University</a>.
				My research interests include Trustworthy AI, Machine Learning, and Multimodal Models, 
				with a recent focus on Multimodal Large Language Models and Reasoning.			
              </p>
              <p align="justify">
				Prior to joining NTU, I was a Research Scientist at the <a href="https://usa.honda-ri.com/">Honda Research Institute USA</a>.
				I received my Ph.D. from <a href="https://www.jhu.edu/">Johns Hopkins University</a> in 2023, 
				and my M.S. and B.S. degrees from <a href="https://en.nycu.edu.tw/">National Chiao Tung University</a> in 2019 and 2017, respectively.
				I also had wonderful experiences as an Applied Scientist Intern with 
				the <a href="https://justwalkout.com/"> Amazon Just Walk Out team</a> in summer 2022 and 
				the <a href="https://www.youtube.com/watch?v=sj1t3msy8dc">Amazon Astro team</a> in summer 2021.
              </p>
              <p align=center>
                <a href="mailto:sylo@csie.ntu.edu.tw">Email</a> &nbsp/&nbsp
                <a href="files/SYLo_CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=vL35nH4AAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/shaoyuanlo"> Github </a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/shaoyuanlo/"> LinkedIn </a> &nbsp/&nbsp
                <a href="https://x.com/shaoyuanlo">Twitter</a>
              </p>
			  <p align=justify>
                <strong>Hiring Undergrad, Master's, and Ph.D. Students!!</strong>
				If you are interested in working with me, please don't hesitate to drop me an email along with your resume and and transcripts.
              </p>
			  <!-- <p align=center>
                <h3 style="color:red;text-align:center">
				I expected to graduate in Spring 2023. I am currently on the job market and looking for Research Scientist roles in the industry.
				</h3>
              </p> -->
            </td>
            <td width="33%">
              <img src="files/sylo3.jpg" height="264" width="220">
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>News</heading>
			  <ul>
                <li>08/2025: &nbsp Joined National Taiwan University as an Assistant Professor!! Awarded as a Yushan Young Fellow!!</li>
              </ul>
			  <ul>
                <li>06/2025: &nbsp 1 paper accepted to IJCV. Serving as an Area Chair for BMVC 2025. Invited talks at ProtagoLabs (remote).</li>
              </ul>			  
			  <ul>
                <li>05/2025: &nbsp 1 paper accepted to ICML 2025 (Spotlight!). Recognized as an Outstanding Reviewer for CVPR 2025!</li>
              </ul>			  
			  <ul>
                <li>04/2025: &nbsp 1 paper accepted to CVIU. Invited talks at UC Santa Cruz and CSIG Wuhan Center (virtual).</li>
              </ul>			  
			  <ul>
                <li>03/2025: &nbsp 1 paper accepted to IEEE T-MI. Invited talks at UC Riverside and WACV 2025 COOOL Workshop.</li>
              </ul>			  
			  <ul>
                <li>02/2025: &nbsp 2 papers accepted to CVPR 2025 (both are Highlight!). Serving as a Tutorial Chair for AVSS 2025.</li>
              </ul>					  
			  <ul>
                <li>01/2025: &nbsp 1 paper accepted to ICLR 2025.</li>
              </ul>			  
			  <ul>
                <li>11/2024: &nbsp Invited talk at National Taiwan University. Serving as an Associate Editor for ICRA 2025.</li>
              </ul>
			  <ul>
                <li>09/2024: &nbsp Invited talk at Jilin University (remote).</li>
              </ul>
			  <ul>
                <li>07/2023: &nbsp 1 paper accepted to ECCV 2024.</li>
              </ul>
              <ul>
                <li>02/2024: &nbsp 2 papers accepted to CVPR 2024. Won the Best Student Paper Award at SPIE Medical Imaging 2024!!</li>
              </ul>			  
              <ul>
                <li>01/2024: &nbsp Invited talks at Academia Sinica and National Yang Ming Chiao Tung University.</li>
              </ul>			  
			  <ul>
                <li>07/2023: &nbsp Joined Honda Research Institute USA as a Research Scientist. See you in San Jose, CA!!</li>
              </ul>
              <ul>
                <li>03/2023: &nbsp Defended my PhD dissertation!!</li>
              </ul>			  			  
              <ul>
                <li>02/2023: &nbsp 1 paper accepted to CVPR 2023.</li>
              </ul>			  
			  <ul>
                <li>09/2022: &nbsp Accepted to the Google CS Research Mentorship Program.</li>
              </ul>	
              <ul>
                <li>07/2022: &nbsp 1 paper accepted to IEEE T-PAMI, and 1 paper accepted to IROS 2022.</li>
              </ul>
			  <ul>
                <li>05/2022: &nbsp Joined Amazon (Just Walk Out team) as an Applied Scientist Intern. See you in Seattle, WA!!</li>
              </ul>			  
              <ul>
                <li>01/2022: &nbsp Invited talks at Academia Sinica and National Yang Ming Chiao Tung University.</li>
              </ul>			  
              <ul>
                <li>12/2021: &nbsp 1 paper accepted to IEEE T-IP.</li>
			  </ul>	
              <ul>
                <li>06/2021: &nbsp Invited talk at CVPR 2021 Tutorial on Adversarial Machine Learning in Computer Vision.</li>
              </ul>					  
			  <ul>
                <li>05/2021: &nbsp Joined Amazon (Astro team) as an Applied Scientist Intern. See you in Bellevue, WA!!</li>
              </ul>			  
              <ul>
                <li>12/2019: &nbsp Won the Best Paper Award at ACM Multimedia Asia 2019!!</li>
              </ul>
			  <ul>
                <li>08/2019: &nbsp Joined Johns Hopkins University as a PhD student. See you in Baltimore, MD!!</li>
              </ul>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="25%" valign="middle">
              <heading>Publications</heading>
            </td>
          </tr>

          <tr>
            <td width="25%"><img src="papers/MMToM.PNG" alt="b3do" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Overcoming Multi-step Complexity in Multimodal Theory-of-Mind Reasoning: A Scalable Bayesian Planner</papertitle>
                <br>
				Chunhui Zhang, &nbsp Zhongyu Ouyang, &nbsp Kwonjoon Lee, &nbsp Nakul Agarwal, &nbsp Sean Dae Houlihan, &nbsp Soroush Vosoughi, &nbsp <strong>Shao-Yuan Lo</strong>
                <br>
                <em>International Conference on Machine Learning (<strong>ICML</strong>)</em>, 2025
                <br>
				<strong>[Spotlight]</strong>
                <br>
				<br>
                <a href="https://arxiv.org/abs/2506.01301">paper</a> / 
				<a href="https://github.com/chunhuizng/scale-bayesian-planner">code</a> / 
				<a href="papers/MMToM_poster.png">poster</a> / 				
                <a href="papers/MMToM.bib">bibtex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td width="25%"><img src="papers/PreSel.PNG" alt="b3do" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Filter Images First, Generate Instructions Later: Pre-Instruction Data Selection for Visual Instruction Tuning</papertitle>
                <br>
				Bardia Safaei, &nbsp Faizan Siddiqui, &nbsp Jiacong Xu, &nbsp Vishal M. Patel, &nbsp <strong>Shao-Yuan Lo</strong>
                <br>
                <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2025
                <br>
				<strong>[Highlight]</strong>
                <br>
				<br>
                <a href="https://arxiv.org/abs/2503.07591">paper</a> / 
				<a href="https://bardisafa.github.io/PreSel/">project</a> / 
				<a href="https://github.com/bardisafa/PreSel">code</a> / 
				<a href="https://www.youtube.com/watch?v=8EePj6CbayY">podcast</a> / 
				<a href="papers/PreSel.bib">bibtex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td width="25%"><img src="papers/Anomaly-OV.PNG" alt="b3do" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Towards Zero-Shot Anomaly Detection and Reasoning with Multimodal Large Language Models</papertitle>
                <br>
				Jiacong Xu, &nbsp <strong>Shao-Yuan Lo</strong>, &nbsp Bardia Safaei, &nbsp Vishal M. Patel, &nbsp Isht Dwivedi
                <br>
                <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2025
                <br>
				<strong>[Highlight]</strong>
                <br>
				<br>
                <a href="https://arxiv.org/abs/2502.07601">paper</a> / 
				<a href="https://xujiacong.github.io/Anomaly-OV/">project</a> / 
				<a href="https://github.com/honda-research-institute/Anomaly-OneVision">code</a> / 
				<a href="talks/CSIG_2025_04_12.pdf">slides</a> / 
				<a href="papers/Anomaly-OV.bib">bibtex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td width="25%"><img src="papers/ComNeck.PNG" alt="b3do" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Bridging Compressed Image Latents and Multimodal Large Language Models</papertitle>
                <br>
				Chia-Hao Kao, &nbsp Cheng Chien, &nbsp Yu-Jen Tseng, &nbsp Yi-Hsin Chen, &nbsp Alessandro Gnutti, 
				&nbsp <strong>Shao-Yuan Lo</strong>, &nbsp Wen-Hsiao Peng, &nbsp Riccardo Leonardi
                <br>
                <em>International Conference on Learning Representations (<strong>ICLR</strong>)</em>, 2025
                <br>
				<br>
                <a href="https://arxiv.org/abs/2407.19651">paper</a> / 
				<a href="https://nycu-mapl.github.io/BridgingCompressionMLLM_page/">project</a> / 
				<a href="https://github.com/NYCU-MAPL/BridgingCompressionMLLM">code</a> / 
				<a href="papers/ComNeck_poster.pdf">poster</a> / 
				<a href="papers/ComNeck.bib">bibtex</a>
              </p>
            </td>
          </tr>		  

          <tr>
            <td width="25%"><img src="papers/StimuVAR.png" alt="b3do" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>StimuVAR: Spatiotemporal Stimuli-aware Video Affective Reasoning with Multimodal Large Language Models</papertitle>
                <br>
				Yuxiang Guo, &nbsp Faizan Siddiqui, &nbsp Yang Zhao, &nbsp Rama Chellappa, &nbsp <strong>Shao-Yuan Lo</strong>
                <br>
                <em>International Journal of Computer Vision (<strong>IJCV</strong>)</em>, 2025
				<br>
				<br>
                <a href="https://arxiv.org/abs/2409.00304">paper</a> / 
				<a href="https://github.com/EthanG97/StimuVAR">code</a> / 
				<a href="papers/StimuVAR.bib">bibtex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td width="25%"><img src="papers/Survey.PNG" alt="b3do" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Egocentric and Exocentric Methods: A Short Survey</papertitle>
                <br>
                Anirudh Thatipelli, &nbsp <strong>Shao-Yuan Lo</strong>, &nbsp Amit K. Roy-Chowdhury
                <br>
                <em>Computer Vision and Image Understanding (<strong>CVIU</strong>)</em>, 2025
                <br>
				<br>
                <a href="https://arxiv.org/abs/2410.20621">paper</a> / 
                <a href="papers/Survey.bib">bibtex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td width="25%"><img src="papers/CG-DDPM.jpg" alt="b3do" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>CBCT Reconstruction using Single X-ray Projection with Cycle-domain Geometry-integrated Denoising Diffusion Probabilistic Models</papertitle>
                <br>
                Shaoyan Pan, &nbsp Junbo Peng, &nbsp Yuan Gao, &nbsp <strong>Shao-Yuan Lo</strong>, &nbsp Tianyu Luan, &nbsp Junyuan Li, &nbsp Tonghe Wang, 
				&nbsp Chih-Wei Chang, &nbsp Zhen Tian, &nbsp Xiaofeng Yang
                <br>
                <em>IEEE Transactions on Medical Imaging (<strong>T-MI</strong>)</em>, 2025
                <br>
				<br>
                <a href="https://ieeexplore.ieee.org/document/10946202">paper</a> / 
                <a href="papers/CG-DDPM.bib">bibtex</a>
              </p>
            </td>
          </tr>	

          <tr>
            <td width="25%"><img src="papers/TTT-Vnet.PNG" alt="b3do" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>TTT-Vnet: A 3D Vision Test-Time Training Model for Medical Image Analysis</papertitle>
                <br>
                Shaoyan Pan, &nbsp Vanessa Su, &nbsp <strong>Shao-Yuan Lo</strong>, &nbsp Mingzhe Hu, &nbsp Yuheng Li, &nbsp Chih-Wei Chang, 
				&nbsp Tonghe Wang, &nbsp Richard L. J. Qiu, &nbsp and Xiaofeng Yang
                <br>
                <em>SPIE Medical Imaging (<strong>SPIE MI</strong>)</em>, 2025
                <br>
				<br>
                <a href="https://spie.org/medical-imaging/presentation/TTT-Vnet--A-3D-vision-test-time-training-model/13406-108">paper</a> / 
                <a href="papers/TTT-Vnet.bib">bibtex</a>
              </p>
            </td>
          </tr>	

          <tr>
            <td width="25%"><img src="papers/AnomalyRuler.PNG" alt="b3do" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Follow the Rules: Reasoning for Video Anomaly Detection with Large Language Models</papertitle>
                <br>
				Yuchen Yang, &nbsp Kwonjoon Lee, &nbsp Behzad Dariush, &nbsp Yinzhi Cao, &nbsp <strong>Shao-Yuan Lo</strong>
                <br>
                <em>European Conference on Computer Vision (<strong>ECCV</strong>)</em>, 2024
				<br>
				<br>
                <a href="https://arxiv.org/abs/2407.10299">paper</a> / 
				<a href="https://github.com/Yuchen413/AnomalyRuler">code</a> / 
				<a href="https://www.youtube.com/watch?v=73HvF2Yu_Q4">talk</a> / 
				<a href="papers/AnomalyRuler.bib">bibtex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td width="25%"><img src="papers/UADT.PNG" alt="b3do" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Uncertainty-aware Action Decoupling Transformer for Action Anticipation</papertitle>
                <br>
				Hongji Guo, &nbsp Nakul Agarwal, &nbsp <strong>Shao-Yuan Lo</strong>, &nbsp Kwonjoon Lee, &nbsp Qiang Ji
                <br>
                <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2024
				<br>
				<strong>[Highlight]</strong>
                <br>
				<br>
                <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Guo_Uncertainty-aware_Action_Decoupling_Transformer_for_Action_Anticipation_CVPR_2024_paper.html">paper</a> / 
				<a href="papers/UADT.bib">bibtex</a>
              </p>
            </td>
          </tr>	

          <tr>
            <td width="25%"><img src="papers/PlausiVL.PNG" alt="b3do" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Can’t Make an Omelette without Breaking Some Eggs: Plausible Action Anticipation using Large Video-Language Models</papertitle>
                <br>
				Himangi Mittal, &nbsp Nakul Agarwal, &nbsp <strong>Shao-Yuan Lo</strong>, &nbsp Kwonjoon Lee
                <br>
                <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2024
                <br>
				<br>
                <a href="https://arxiv.org/abs/2405.20305">paper</a> / 
				<a href="papers/PlausiVL.bib">bibtex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td width="25%"><img src="papers/X-CBCT-DDPM.PNG" alt="b3do" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Patient-specific 3D Volumetric CBCT Image Reconstruction with Single X-ray Projection Using Denoising Diffusion Probabilistic Model</papertitle>
                <br>
                Shaoyan Pan, &nbsp <strong>Shao-Yuan Lo</strong>, &nbsp Chih-Wei Chang, &nbsp Ella Salari, &nbsp Tonghe Wang, &nbsp Justin Roper,
                &nbsp Aparna H. Kesarwala, &nbsp Xiaofeng Yang
                <br>
                <em>SPIE Medical Imaging (<strong>SPIE MI</strong>)</em>, 2024
                <br>
				<strong>[Best Student Paper Award]</strong>
                <br>
				<br>
                <a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/12931/129310P/Patient-specific-3D-volumetric-CBCT-image-reconstruction-with-single-x/10.1117/12.3006561.short">paper</a> / 
                <a href="papers/X-CBCT-DDPM.bib">bibtex</a>
              </p>
            </td>
          </tr>	

		  <tr>
            <td width="25%"><img src="papers/ABNN.png" alt="b3do" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Adaptive Batch Normalization Networks for Adversarial Robustness</papertitle>
                <br>
                <strong>Shao-Yuan Lo</strong>, &nbsp Vishal M. Patel
                <br>
                <em>IEEE International Conference on Advanced Video and Signal-based Surveillance (<strong>AVSS</strong>)</em>, 2024
				<br>
				<strong>[Oral]</strong>
                <br>
				<br>
                <a href="https://arxiv.org/abs/2405.11708">paper</a> / 
				<a href="papers/ABNN.pdf">slides</a> / 
				<a href="papers/ABNN_poster.pdf">poster</a> / 
                <a href="papers/ABNN.bib">bibtex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td width="25%"><img src="papers/STPL.png" alt="b3do" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Spatio-Temporal Pixel-Level Contrastive Learning-based Source-Free Domain Adaptation for Video Semantic Segmentation</papertitle>
                <br>
				<strong>Shao-Yuan Lo</strong>, &nbsp Poojan Oza, &nbsp Sumanth Chennupati, &nbsp Alejandro Galindo, &nbsp Vishal M. Patel
                <br>
                <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2023
                <br>
				<br>
                <a href="https://arxiv.org/abs/2303.14361">paper</a> / 
				<a href="papers/STPL.pdf">slides</a> / 
				<a href="papers/STPL_poster.pdf">poster</a> / 
                <a href="papers/STPL.bib">bibtex</a>
              </p>
            </td>
          </tr>	

          <tr>
            <td width="25%"><img src="papers/AFAMI.png" alt="b3do" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Deep Learning-based Multi-Organ CT Segmentation with Adversarial Data Augmentation</papertitle>
                <br>
                Shaoyan Pan, &nbsp <strong>Shao-Yuan Lo</strong>, &nbsp Min Huang, &nbsp Chaoqiong Ma, &nbsp Jacob Wynne, &nbsp Tonghe Wang,
                &nbsp Tian Liu, &nbsp Xiaofeng Yang
                <br>
                <em>SPIE Medical Imaging (<strong>SPIE MI</strong>)</em>, 2023
                <br>
				<br>
                <a href="https://arxiv.org/abs/2302.13172">paper</a> / 
                <a href="papers/AFAMI.bib">bibtex</a>
              </p>
            </td>
          </tr>	

          <tr>
            <td width="25%"><img src="papers/PrincipaLS.png" alt="b3do" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Adversarially Robust One-class Novelty Detection</papertitle>
                <br>
                <strong>Shao-Yuan Lo</strong>, &nbsp Poojan Oza, &nbsp Vishal M. Patel
                <br>
                <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>T-PAMI</strong>)</em>, 2022
                <br>
				<strong>[Featured in IEEE CTSoc News on Consumer Technology, April 2024]</strong>
                <br>
				<br>
                <a href="https://arxiv.org/abs/2108.11168">paper</a> / 
				<a href="papers/PrincipaLS.pdf">slides</a> / 
				<a href="https://ctsoc.ieee.org/images/CTSOC-NCT-2024-04.pdf">IEEE CTSoc News</a> / 
                <a href="papers/PrincipaLS.bib">bibtex</a>
              </p>
            </td>
          </tr>	
		  
		  <tr>
            <td width="25%"><img src="papers/LFDA.png" alt="b3do" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Learning Feature Decomposition for Domain Adaptive Monocular Depth Estimation</papertitle>
                <br>
                <strong>Shao-Yuan Lo</strong>, &nbsp Wei Wang, &nbsp Jim Thomas, &nbsp Jingjing Zheng, &nbsp Vishal M. Patel, &nbsp Cheng-Hao Kuo
                <br>
                <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (<strong>IROS</strong>)</em>, 2022
                <br>
				<br>
                <a href="https://arxiv.org/abs/2208.00160">paper</a> / 
                <a href="https://www.amazon.science/blog/transferring-depth-estimation-knowledge-between-cameras">blog</a> / 
                <a href="papers/LFDA.bib">bibtex</a>
              </p>
            </td>
          </tr>	
		  
		  <tr>
            <td width="25%"><img src="papers/ARTUDA.png" alt="b3do" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Exploring Adversarially Robust Training for Unsupervised Domain Adaptation</papertitle>
                <br>
                <strong>Shao-Yuan Lo</strong>, &nbsp Vishal M. Patel
                <br>
                <em>Asian Conference on Computer Vision (<strong>ACCV</strong>)</em>, 2022
                <br>
				<br>
                <a href="https://arxiv.org/abs/2202.09300">paper</a> / 
				<a href="papers/ARTUDA.pdf">slides</a> / 
                <a href="papers/ARTUDA.bib">bibtex</a>
              </p>
            </td>
          </tr>	
		  
		  <tr>
            <td width="25%"><img src="papers/MultiBN.png" alt="b3do" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Defending Against Multiple and Unforeseen Adversarial Videos</papertitle>
                <br>
                <strong>Shao-Yuan Lo</strong>, &nbsp Vishal M. Patel
                <br>
                <em>IEEE Transactions on Image Processing (<strong>T-IP</strong>)</em>, 2021
                <br>
				<strong>[Journal presentation at ICIP 2022]</strong>
                <br>
				<br>
                <a href="https://arxiv.org/abs/2009.05244">paper</a> / 
				<a href="papers/MultiBN.pdf">slides</a> / 
                <a href="papers/MultiBN.bib">bibtex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td width="25%"><img src="papers/Halftone.png" alt="b3do" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Error Diffusion Halftoning Against Adversarial Examples</papertitle>
                <br>
                <strong>Shao-Yuan Lo</strong>, &nbsp Vishal M. Patel
                <br>
                <em>IEEE International Conference on Image Processing (<strong>ICIP</strong>)</em>, 2021
                <br>
				<br>
                <a href="https://arxiv.org/abs/2101.09451">paper</a> / 
				<a href="papers/Halftone.pdf">slides</a> / 
                <a href="papers/Halftone.bib">bibtex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td width="25%"><img src="papers/OUDefend.PNG" alt="b3do" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Overcomplete Representations Against Adversarial Videos</papertitle>
                <br>
                <strong>Shao-Yuan Lo</strong>, &nbsp Jeya Maria Jose Valanarasu, &nbsp Vishal M. Patel
                <br>
                <em>IEEE International Conference on Image Processing (<strong>ICIP</strong>)</em>, 2021
                <br>
				<br>
                <a href="https://arxiv.org/abs/2012.04262">paper</a> / 
				<a href="papers/OUDefend.pdf">slides</a> / 
                <a href="papers/OUDefend.bib">bibtex</a>
              </p>
            </td>
          </tr>

		  <tr>
            <td width="25%"><img src="papers/MultAV.PNG" alt="b3do" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>MultAV: Multiplicative Adversarial Videos</papertitle>
                <br>
                <strong>Shao-Yuan Lo</strong>, &nbsp Vishal M. Patel
                <br>
                <em>IEEE International Conference on Advanced Video and Signal-based Surveillance (<strong>AVSS</strong>)</em>, 2021
                <br>
				<br>
                <a href="https://arxiv.org/abs/2009.08058">paper</a> / 
				<a href="papers/MultAV.pdf">slides</a> / 
                <a href="papers/MultAV.bib">bibtex</a>
              </p>
            </td>
          </tr> 

          <tr>
            <td width="25%"><img src="papers/EDANet.PNG" alt="b3do" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Efficient Dense Modules of Asymmetric Convolution for Real-Time Semantic Segmentation</papertitle>
                <br>
                <strong>Shao-Yuan Lo</strong>, &nbsp Hsueh-Ming Hang, &nbsp Sheng-Wei Chan, &nbsp Jing-Jhih Lin
                <br>
                <em>ACM International Conference on Multimedia in Asia (<strong>ACM MM Asia</strong>)</em>, 2019
				<br>
				<font color="red">[Best Paper Award]</font>
                <br>
				<br>
                <a href="https://arxiv.org/abs/1809.06323">paper</a> / 
                <a href="https://github.com/shaoyuanlo/EDANet">project page</a> / 
                <a href="papers/EDANet.pdf">slides</a> / 
                <a href="papers/EDANet.bib">bibtex</a>
              </p>
            </td>
          </tr>
		  
          <tr>
            <td width="25%"><img src="papers/DCT.PNG" alt="b3do" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Exploring Semantic Segmentation on the DCT Representation</papertitle>
                <br>
                <strong>Shao-Yuan Lo</strong>, &nbsp Hsueh-Ming Hang
                <br>
                <em>ACM International Conference on Multimedia in Asia (<strong>ACM MM Asia</strong>)</em>, 2019
				<br>
				<strong>[Oral]</strong>
                <br>
				<br>
                <a href="https://arxiv.org/abs/1907.10015">paper</a> / 
                <a href="papers/DCT.pdf">slides</a> / 
                <a href="papers/DCT.bib">bibtex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td width="25%"><img src="papers/MultiClass.PNG" alt="b3do" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Multi-Class Lane Semantic Segmentation using Efficient Convolutional Networks</papertitle>
                <br>
                <strong>Shao-Yuan Lo</strong>, &nbsp Hsueh-Ming Hang, &nbsp Sheng-Wei Chan, &nbsp Jing-Jhih Lin
                <br>
                <em>IEEE International Workshop on Multimedia Signal Processing (<strong>MMSP</strong>)</em>, 2019
				<br>
				<br>
                <a href="https://arxiv.org/abs/1907.09438">paper</a> / 
                <a href="papers/MultiClass.pdf">slides</a> / 
                <a href="papers/MultiClass.bib">bibtex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td width="25%"><img src="papers/LDFNet.PNG" alt="b3do" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Incorporating Luminance, Depth and Color Information by a Fusion-based Network for Semantic Segmentation</papertitle>
                <br>
                Shang-Wei Hung, &nbsp <strong>Shao-Yuan Lo</strong>, &nbsp Hsueh-Ming Hang
                <br>
                <em>IEEE International Conference on Image Processing (<strong>ICIP</strong>)</em>, 2019
				<br>
				<strong>[Oral]</strong>
                <br>
				<br>
                <a href="https://arxiv.org/abs/1809.09077">paper</a> / 
                <a href="https://github.com/shangweihung/LDFNet">project page</a> / 
                <a href="papers/LDFNet.pdf">slides</a> / 
                <a href="papers/LDFNet.bib">bibtex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td width="25%"><img src="papers/LMD.PNG" alt="b3do" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Efficient Road Lane Marking Detection with Deep Learning</papertitle>
                <br>
                Ping-Rong Chen*, &nbsp <strong>Shao-Yuan Lo*</strong>, &nbsp Hsueh-Ming Hang, &nbsp Sheng-Wei Chan, &nbsp Jing-Jhih Lin
                <br>
                <em>IEEE International Conference on Digital Signal Processing (<strong>DSP</strong>)</em>, 2018
                <br>
				<br>
                <a href="https://arxiv.org/abs/1809.03994">paper</a> / 
                <a href="papers/LMD.pdf">slides</a> / 
                <a href="papers/LMD.bib">bibtex</a>
              </p>
            </td>
          </tr>		  
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="25%" valign="middle">
              <heading>Dissertations</heading>
            </td>
          </tr>

          <tr>
            <td width="25%"><img src="files/JHU_logo.png" alt="b3do" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Robust Computer Vision Against Adversarial Examples and Domain Shifts</papertitle>
                <br>
				<strong>Shao-Yuan Lo</strong>
                <br>
                <em>Ph.D. Thesis, Johns Hopkins University</em>, 2023
                <br>
				<br>
                <a href="https://jscholarship.library.jhu.edu/items/497a35ef-81cc-44f3-b9a9-b01b182a1a96">thesis</a> / 
                <a href="papers/PhD.bib">bibtex</a>
              </p>
            </td>
          </tr>	
		  
		  <tr>
            <td width="25%"><img src="files/NCTU_logo.png" alt="b3do" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Real-Time Semantic Segmentation Networks for Autonomous Driving</papertitle>
                <br>
				<strong>Shao-Yuan Lo</strong>
                <br>
                <em>Master Thesis, National Chiao Tung University</em>, 2019
                <br>
				<br>
                <a href="https://hdl.handle.net/11296/7acbjd">thesis</a> / 
                <a href="papers/Master.bib">bibtex</a>
              </p>
            </td>
          </tr>	
        </table>
		
		<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Industrial Experience</heading>
                <ul> <li>
				  <strong>Research Scientist</strong> at 
				  <a href="https://usa.honda-ri.com/"> Honda Research Institute USA</a>, San Jose, CA &nbsp (July 2023 - Now)
				</li> </ul>			  
                <ul> <li>
				  <strong>Applied Scientist Intern</strong> at 
				  <a href="https://justwalkout.com/"> Amazon (Just Walk Out team)</a>, Seattle, WA &nbsp (May 2022 - Aug 2022)
				</li> </ul>
				<ul> <li>
				  <strong>Applied Scientist Intern</strong> at 
				  <a href="https://www.youtube.com/watch?v=sj1t3msy8dc"> Amazon (Astro team)</a>, Bellevue, WA &nbsp (May 2021 - Aug 2021)
				</li> </ul>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Awards</heading>
				<ul> <li>
				  <strong> <a href="https://yushan.project.edu.tw/TopTalent/EN">
				  Yushan Young Fellow</a></strong>, &nbsp Ministry of Education, Taiwan (2025)
				</li> </ul>			  
				<ul> <li>
				  <strong> <a href="https://cvpr.thecvf.com/Conferences/2025/ProgramCommittee">
				  Outstanding Reviewer</a></strong>, &nbsp IEEE/CVF CVPR 2025 (2025)
				</li> </ul>			  
                <ul> <li>
				  <strong> <a href="https://spie.org/conferences-and-exhibitions/medical-imaging/program/conferences/awards#_=_">
				  Robert F. Wagner All-Conference Best Student Paper Award</a></strong>, &nbsp SPIE Medical Imaging 2024 (2024)
				</li> </ul>			  
				<ul> <li>
				  <strong> <a href="https://cvpr2023.thecvf.com/Conferences/2023">
				  CVPR Travel Award</a></strong>, &nbsp IEEE/CVF CVPR 2023 (2023)
				</li> </ul>			  
				<ul> <li>
				  <strong> <a href="https://research.google/outreach/csrmp">
				  Google CS Research Mentorship Program</a></strong>, &nbsp Google Research (2022)
				</li> </ul>
                <ul> <li>
				  <strong> <a href="https://depart.moe.edu.tw/ED2500/cp.aspx?n=ECEA48027CA1AA4E&s=FDC3BA2C714CD75F">
				  Government Scholarship to Study Abroad</a></strong>, &nbsp Ministry of Education, Taiwan (2020)
				</li> </ul>
                <ul> <li>
				  <strong>First-Year Doctoral Fellowship</strong>, &nbsp Johns Hopkins University (2019)
				</li> </ul>
                <ul> <li>
				  <strong> <a href="https://depart.moe.edu.tw/ED2500/News.aspx?n=92DC002FDE1CC633&page=1&PageSize=20">
				  Government Scholarship to World Top 100 Universities</a></strong>, &nbsp Ministry of Education, Taiwan (2019)
				</li> </ul>				
                <ul> <li>
				  <strong> <a href="http://www.acmmmasia.org/2019/files/ACMMMASIA2019-Program.pdf">
				  Best Paper Award</a></strong>, &nbsp ACM Multimedia Asia 2019 (2019)
				</li> </ul>
                <ul> <li>
				  <strong> <a href="https://140.125.183.142/wp-content/uploads/2021/09/IPPR%E7%AC%AC%E5%8D%81%E4%BA%8C%E5%B1%86%E5%8D%9A%E7%A2%A9%E5%A3%AB%E8%AB%96%E6%96%87%E7%8D%8E%E5%BE%97%E7%8D%8E%E8%B3%87%E6%96%99.pdf">
				  Best Master Thesis Award</a></strong>, &nbsp Chinese Image Processing and Pattern Recognition Society (2019)
				</li> </ul>
                <ul> <li>
				  <strong> <a href="https://infonews-fornthu.nctu.edu.tw/index.php?topflag=1&SuperType=2&SuperTypeNo=2&type=%A6%E6%ACF&id=20190500241&action=detail">
				  Students’ Outstanding Contribution Award</a></strong>, &nbsp National Chiao Tung University (2019)
				</li> </ul>
                <ul> <li>
				  <strong>Dean's List</strong>, &nbsp National Chiao Tung University (2017)
				</li> </ul>				
                <ul> <li>
				  <strong>Scholarship to Overseas Exchange Program</strong>, &nbsp National Chiao Tung University (2016)
				</li> </ul>			  
                <ul> <li>
				  <strong> <a href="https://tw.news.yahoo.com/%25E4%25BA%25A4%25E5%25A4%25A7%25E6%25A0%25A1%25E5%258F%258B%25E5%258B%259D%25E8%258F%25AF%25E7%25A7%2591%25E6%258A%2580%25E8%2591%25A3%25E5%25BA%25A7%25E6%258F%2590%25E4%25BE%259B%25E5%258D%2583%25E8%2590%25AC%25E7%258D%258E%25E5%25AD%25B8%25E9%2587%2591%25E7%25B5%25A6%25E5%2584%25AA%25E7%25A7%2580%25E5%25AD%25B8%25E5%25BC%259F%25E5%25A6%25B9-215319757.html">
				  WINTEK Outstanding Freshman Scholarship</a></strong>, &nbsp WINTEK Corp. and National Chiao Tung University (2013)
				</li> </ul>
            </td>
          </tr>
        </table>
		
		<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Invited Talks</heading>
				<ul> <li>
				  06/30/2025: &nbsp “<a href="talks/ProtagoLabs_2025_06_30.pdf">Anomaly Detection in the Era of Multimodal Large Language Models</a>.”
				  At ProtagoLabs, VA (Remote).
				  Host: Dr. <a href="https://scholar.google.com/citations?user=2KNy5XIAAAAJ">Xing Di</a>.
				</li> </ul>					  
				<ul> <li>
				  04/15/2025: &nbsp “<a href="talks/UCSC_2025_04_15.pdf">Anomaly Detection in the Era of Multimodal Large Language Models</a>.”
				  At the University of California, Santa Cruz.
				  Host: Prof. <a href="https://cihangxie.github.io/">Cihang Xie</a> and Prof. <a href="https://yuyinzhou.github.io/">Yuyin Zhou</a>.
				</li> </ul>				  
				<ul> <li>
				  04/12/2025: &nbsp “<a href="talks/CSIG_2025_04_12.pdf">Towards Zero-Shot Anomaly Detection and Reasoning with Multimodal Large Language Models</a>.” At the 
				  <a href="https://mp.weixin.qq.com/s/opOMTAN2s7kLVwVaNfwAfg">China Society of Image and Graphics (CSIG) Wuhan Center</a>, Virtual.
				  Host: Prof. <a href="https://caoyunkang.github.io/">Yunkang Cao</a>.
				</li> </ul>				  
				<ul> <li>
				  03/10/2025: &nbsp “<a href="talks/UCR_2025_03_10.pdf">Anomaly Detection in the Era of Multimodal Large Language Models</a>.”
				  At the University of California, Riverside.
				  Host: Prof. <a href="https://vcg.ece.ucr.edu/amit">Amit K. Roy-Chowdhury</a>.
				</li> </ul>			  
                <ul> <li>
				  03/04/2025: &nbsp “<a href="talks/WACV25_COOOL_2025_03_04.pdf">Anomaly Detection in the Era of Multimodal Large Language Models</a>.” At 
				  <a href="https://sites.google.com/ucr.edu/cooolsworkshop/home">WACV 2025 Workshop on Out-of-Label Hazards in Autonomous Driving</a>.
				  Host: Dr. <a href="https://abhishekaich27.github.io/">Abhishek Aich</a> and Dr. <a href="https://www.alialshami87.com/">Ali AlShami</a>.
				</li> </ul>			  
				<ul> <li>
				  11/04/2024: &nbsp “<a href="talks/NTUEE_2024_11_04_web.pdf">AI Safety and Beyond: Robustness, Monitoring, and Alignment</a>.”
				  At National Taiwan University, Taiwan.
				  Host: Prof. <a href="https://cc.ee.ntu.edu.tw/~ihsiangw/">I-Hsiang Wang</a>.
				</li> </ul>
				<ul> <li>
				  09/19/2024: &nbsp “<a href="talks/JLU_2024_09_19_web.pdf">Multimodal Large Language Models for Driving Safety Applications</a>.”
				  At Jilin University, China (Remote).
				  Host: Prof. <a href="https://ccst.jlu.edu.cn/info/1359/18959.htm">Hongxia Xie</a>.
				</li> </ul>
			    <ul> <li>
				  01/09/2024: &nbsp “<a href="talks/CCVL_2023_04_14.pdf">Robust Computer Vision Against Adversarial Examples and Domain Shifts</a>.”
				  At National Yang Ming Chiao Tung University, Taiwan.
				  Host: Prof. <a href="https://sites.google.com/g2.nctu.edu.tw/wpeng/cv">Wen-Hsiao Peng</a>.
				</li> </ul>
                <ul> <li>
				  12/14/2023: &nbsp “<a href="talks/CCVL_2023_04_14.pdf">Robust Computer Vision Against Adversarial Examples and Domain Shifts</a>.”
				  At Academia Sinica, Taiwan.
				  Host: Prof. <a href="https://www.citi.sinica.edu.tw/pages/pullpull/index_en.html">Jun-Cheng Chen</a>.
				</li> </ul>		
                <ul> <li>
				  04/14/2023: &nbsp “<a href="talks/CCVL_2023_04_14.pdf">Robust Computer Vision Against Adversarial Examples and Domain Shifts</a>.”
				  At Computational Cognition, Vision, and Learning (CCVL) Lab, Johns Hopkins University.
				  Host: Prof. <a href="https://www.cs.jhu.edu/~ayuille/">Alan Yuille</a>.
				</li> </ul>	  
                <ul> <li>
				  01/10/2022: &nbsp “<a href="talks/Sinica_2022_01_10_NCTU.pdf">Defending Against Multiple and Unforeseen Adversarial Videos</a>.” 
				  At National Yang Ming Chiao Tung University, Taiwan.
				  Host: Prof. <a href="https://sites.google.com/g2.nctu.edu.tw/wpeng/cv">Wen-Hsiao Peng</a>.
				</li> </ul>
                <ul> <li>
				  01/05/2022: &nbsp “<a href="talks/Sinica_2022_01_05.pdf">Defending Against Multiple and Unforeseen Adversarial Videos</a>.”
				  At Academia Sinica, Taiwan.
				  Host: Prof. <a href="https://www.citi.sinica.edu.tw/pages/pullpull/index_en.html">Jun-Cheng Chen</a>.
				</li> </ul>				
                <ul> <li>
				  06/19/2021: &nbsp “<a href="talks/CVPR21_tutorial.pdf">Adversarial Attacks and Defenses in Videos</a>.” At 
				  <a href="https://advmlincv.github.io/cvpr21-tutorial/">CVPR 2021 Tutorial on Adversarial Machine Learning in Computer Vision</a>, Virtual.
				  Host: Prof. <a href="https://cihangxie.github.io/">Cihang Xie</a>.
				</li> </ul>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Academic Activities</heading>
				<ul> <li>
				  <strong>Organizer</strong>: &nbsp ICCV 2025 2COOOL Workshop
				</li> </ul>			  
				<ul> <li>
				  <strong>Tutorial Chair</strong>: &nbsp AVSS 2025
				</li> </ul>			  
				<ul> <li>
				  <strong>Associate Editor</strong>: &nbsp ICRA 2025
				</li> </ul>
				<ul> <li>
				  <strong>Area Chair</strong>: &nbsp BMVC 2025, &nbsp CVPR 2024 AI4CG Workshop
				</li> </ul>
                <ul> <li>
				  <strong>Journal Reviewer</strong>: &nbsp IEEE T-PAMI, &nbsp IEEE T-IP, &nbsp IEEE RA-L, &nbsp IEEE T-CSVT, &nbsp IEEE T-SMC, 
				  &nbsp IEEE JETCAS, &nbsp IJCV, &nbsp Pattern Recognition, &nbsp Neurocomputing, &nbsp Medical Physics
				</li> </ul>
                <ul> <li>
				  <strong>Conference Reviewer</strong>: &nbsp CVPR, &nbsp ICCV, &nbsp ECCV, &nbsp NeurIPS, &nbsp ICLR, &nbsp ICML,
				  &nbsp AAAI, &nbsp IJCAI, &nbsp ACM MM, &nbsp WACV, &nbsp ACCV, &nbsp ICIP, &nbsp ICPR, &nbsp AVSS
				</li> </ul>
				<ul> <li>
				  <strong>Teaching Assistant</strong>: &nbsp Deep Learning (EN.520.638), Johns Hopkins University, Spring (2021, 2022, 2023)
				</li> </ul>	
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Press Coverage</heading>
				<ul> <li>
				  10/11/2022: &nbsp I was reported on <a href="https://www.ftvnews.com.tw/news/detail/2022A11F04M1">Formosa Television (民視新聞)</a>, 
				  <a href="https://www.youtube.com/watch?v=4BCV3De5QuE">EBC News (東森新聞)</a>, and 
				  <a href="https://www.ntdtv.com.tw/b5/20221022/video/345977.html">New Tang Dynasty Television (新唐人電視台)</a>
				  when I was seving as the Vice President of the Taiwanese Student Association at Johns Hopkins University.
				</li> </ul>	
                <ul> <li>
				  06/01/2019: &nbsp I was reported on <a href="https://news.ltn.com.tw/news/life/breakingnews/2809162">Liberty Times (自由時報)</a>, 
				  <a href="https://udn.com/news/story/6928/3847789">United Daily News (聯合報)</a>, and 
				  <a href="https://www.ctee.com.tw/news/20190601700219-431401">Commercial Times (工商時報)</a>
				  when I was graduating from National Chiao Tung University.
				</li> </ul>			  
                <ul> <li>
				  07/19/2013: &nbsp I was reported on <a href="https://www.chinatimes.com/newspapers/20130719000490-260107?chdtv">China Times (中國時報)</a>
				  when I was graduating from senior high school (National Experimental High School at Hsinchu Science Park).
				</li> </ul>				
                <ul> <li>
				  06/04/2010: &nbsp I was reported on <a href="https://news.ltn.com.tw/news/local/paper/400837">Liberty Times (自由時報)</a>
				  when I was graduating from junior high school.
				</li> </ul>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td><br>
              <p align="left">
                <a href="https://www.easycounter.com/">
                <img src="https://www.easycounter.com/counter.php?ww8411ww"
                border="0" alt="stats counter"></a>
				<font size="2"> &nbsp unique visitors since Oct 2020 </font>
              </p>
            </td>		  
            <td><br>
              <p align="right">
                <font size="2">
                  Template from <a href="https://jonbarron.info/">Jon Barron</a>
                </font>
              </p>
            </td>		
          </tr>
        </table>

        <script type="text/javascript">
          var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
        </script>
        <script type="text/javascript">
          try {
            var pageTracker = _gat._getTracker("UA-7580334-1");
            pageTracker._trackPageview();
          } catch (err) { }
        </script>
      </td>
    </tr>
  </table>
</body>

</html>
